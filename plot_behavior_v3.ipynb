{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "figure_folder = 'figures-v3'\n",
    "os.makedirs(figure_folder, exist_ok=True)\n",
    "\n",
    "n_ms_per_s= 1000\n",
    "n_total_trial= 100\n",
    "\n",
    "curation_XZ = {\n",
    "    'M15_2': {\n",
    "        'CA1': (4.5, [1, 16, 17, 18, 25, 26, 27, 35, 42, 53]),\n",
    "        # Noisy 'M1': [], \n",
    "    }, \n",
    "    'M15_3': {\n",
    "        'M1': (5.5, [17, 18]), \n",
    "        # Noisy 'CA1': (), \n",
    "    }, \n",
    "    'M15_5': {\n",
    "        'CA1': (3.5, [8, 9, 10, 15, 21, 62]),\n",
    "        'M1': (3.5, [28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44]),\n",
    "    }, \n",
    "    'M15_7': {\n",
    "        'CA1': (4.5, [11, 12, 13, 22, 23]),\n",
    "        'M1': (3.5, [23, 24, 25, 29, 30, 32, 37, 41, 42, 44, 45, 46, 47, 51, 52, 53, 56, 57, 58]),\n",
    "    }, \n",
    "    'M16_1': {\n",
    "        'CA1': (5.5, [1, 2, 4, 5, 8, 19, 28, 29, 34, 36, 38, 39, 41, 42, 43, 67, 69, 70]),\n",
    "        # Noisy 'M1': (), \n",
    "    },\n",
    "}\n",
    "\n",
    "curation = {\n",
    "    'M15_2': {\n",
    "        'CA1': (3.5, [1, 6, 7, 8, 9, 10, 11, 13, 15,16,20,21, 22, 23, 24, 29, 36, 44, 45, 48]),\n",
    "        # Noisy 'M1': [], \n",
    "    }, \n",
    "    'M15_3': {\n",
    "       'CA1': (3.5, [25, 29, 34]), \n",
    "        'M1': (3.5, [23, 24]), \n",
    "\n",
    "    }, \n",
    "    'M15_5': {\n",
    "        'CA1': (3.5, [4, 5, 7, 8, 9, 10, 11, 12, 15, 21, 62, 66]),\n",
    "        'M1': (3.5, [28, 29, 31, 33, 34,35, 36, 37, 38, 39, 40, 41, 42, 43, 44]),\n",
    "    }, \n",
    "    'M15_7': {\n",
    "        'CA1': (3.5, [7, 11, 12, 13,14, 19, 20]),\n",
    "        'M1': (3.5, [4, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30,31,  32,35, 36,  37, 38, 41, 42, 44, 45, 46, 47,48,  51, 52, 53, 55, 56, 57, 58,59,62]),\n",
    "    }, \n",
    "    'M16_1': {\n",
    "        'CA1': (3.5, [1, 2,3,  4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 22, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 54, 57, 58, 59, 60, 61, 62]),\n",
    "        # Noisy 'M1': (), \n",
    "    },\n",
    "}    \n",
    "\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "for subject, subject_curation in curation.items():\n",
    "    for region, (threshold, curated_units) in subject_curation.items():\n",
    "        output_folder = f'{figure_folder}/curated/{region}'        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for unit_id in curated_units:\n",
    "            if not os.path.isfile(f'{output_folder}/{subject}-{threshold}-{unit_id}.png'):\n",
    "                shutil.copy2(f'data/processed/{subject}/{region}/curations-{threshold}/{unit_id}.png', f'{output_folder}/{subject}-{threshold}-{unit_id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "\n",
    "session_palette = {\n",
    "    session_index + 1: color for session_index, color in enumerate(['#D1D9EC', '#a2b1d8', '#8597c6', '#697fb7', '#ffbcbb', '#ffb5b4', '#ffaeac', '#ffa6a5', '#e44e4b', '#d93f3c', '#cc3330', '#b03533', '#ddde29', '#bcbd21'])\n",
    "}\n",
    "\n",
    "joystick_length = 15\n",
    "hw = 2048\n",
    "n_s_per_min = 60\n",
    "n_ms_per_s = 1000\n",
    "joystick_threshold = 0.15\n",
    "n_total_trial = 100\n",
    "\n",
    "def analog_to_digital(analog, max_joystick_angle=22.5):\n",
    "    return joystick_length * (np.sin(np.deg2rad(max_joystick_angle * analog/hw)))\n",
    "\n",
    "reaction_times = []\n",
    "for subject in ['M15_2', 'M15_3', 'M15_5', 'M15_7', 'M16_1']:\n",
    "    session_paths = sorted(glob.glob(f'data/raw/controller/**/{subject.replace(\"_\", \"-\")}.TXT'))\n",
    "\n",
    "    for session_index, session_path in enumerate(session_paths):\n",
    "        events = pd.read_csv(session_path)\n",
    "        # If there are multiple headers that day, the last header marks the start of the actual experiment. This might happen when we use the subject RFID tag duing the equipment check.\n",
    "        state_ids = np.where(events['state'] == 'state')[0]\n",
    "        if len(state_ids) > 0:\n",
    "            events = events.iloc[state_ids[-1]+1:].reset_index(drop=True)\n",
    "            events['x'] = pd.to_numeric(events['x'])\n",
    "            events['y'] = pd.to_numeric(events['y'])\n",
    "            events['time'] = pd.to_numeric(events['time'])\n",
    "            events['state'] = pd.to_numeric(events['state'])\n",
    "            events['trial'] = pd.to_numeric(events['trial'])\n",
    "            events['s_trial'] = pd.to_numeric(events['s_trial'])\n",
    "            events['f_trial'] = pd.to_numeric(events['f_trial'])\n",
    "\n",
    "        events['x'] = analog_to_digital(events['x'])\n",
    "        events['y'] = analog_to_digital(events['y'])\n",
    "        events['position'] = np.sqrt(events['x'] ** 2 + events['y'] ** 2)\n",
    "        events['time'] = events['time'] - events['time'][0]\n",
    "        events['time'] = events['time'] / n_ms_per_s \n",
    "\n",
    "        for trial in range(n_total_trial):\n",
    "            trial_indices = np.where(events['trial'] == trial)[0]\n",
    "            if any(events['state'][trial_indices] == 1):\n",
    "                trial_reaction_index = np.where((events['trial'] == trial) & (events['state'] == 1))[0][0]\n",
    "                reaction_times.append({\n",
    "                    'subject': subject,\n",
    "                    'session': session_index+1,\n",
    "                    'reaction': events['time'][trial_reaction_index] - events['time'][trial_indices.min()],\n",
    "                })\n",
    "        \n",
    "reaction_times = pd.DataFrame(reaction_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 15))\n",
    "for session in range(1, reaction_times['session'].max()+1):\n",
    "    ax = plt.subplot(len(reaction_times['session'].unique())+1, 1, session)\n",
    "    sns.kdeplot(data=reaction_times[reaction_times['session']==session], x='reaction', label=f'Session {session+1}', ax=ax, fill=True, color=session_palette[session],edgecolor='black', alpha=0.5)\n",
    "    ax.set_ylim(0, 0.28)\n",
    "    ax.set_xlim(-3, 12)\n",
    "    ax.set_ylabel(session)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "ax.set_axis_on()\n",
    "fig.suptitle(f'Reaction time distribution')\n",
    "plt.savefig(f'{figure_folder}/reaction_density.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in ['M15_2', 'M15_3', 'M15_5', 'M15_7', 'M16_1']:\n",
    "    stats = reaction_times[reaction_times['subject']==subject]\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    for session in range(1, stats['session'].max()+1):\n",
    "        ax = plt.subplot(len(stats['session'].unique())+1, 1, session)\n",
    "        sns.kdeplot(data=stats[stats['session']==session], x='reaction', label=f'Session {session+1}', ax=ax, fill=True, color=session_palette[session],edgecolor='black', alpha=0.5)\n",
    "        ax.set_ylim(0, 0.15)\n",
    "        ax.set_xlim(-3, 13)\n",
    "        ax.set_ylabel(session)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_axis_off()\n",
    "    ax.set_axis_on()\n",
    "    fig.suptitle(f'{subject} - Reaction time distribution')\n",
    "    plt.savefig(f'{figure_folder}/{subject}_reaction_density.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "joystick_length = 15\n",
    "hw = 2048\n",
    "n_s_per_min = 60\n",
    "n_ms_per_s = 1000\n",
    "joystick_threshold = 0.15\n",
    "n_total_trial = 100\n",
    "\n",
    "def analog_to_digital(analog, max_joystick_angle=22.5):\n",
    "    return joystick_length * (np.sin(np.deg2rad(max_joystick_angle * analog/hw)))\n",
    "\n",
    "half_successes = []\n",
    "successes = []\n",
    "for subject in ['M15_2', 'M15_3', 'M15_5', 'M15_7', 'M16_1']:\n",
    "    session_paths = sorted(glob.glob(f'data/raw/controller/**/{subject.replace(\"_\", \"-\")}.TXT'))\n",
    "    for session_index, session_path in enumerate(session_paths):\n",
    "        events = pd.read_csv(session_path)\n",
    "        half_successes.append({\n",
    "            'rate': events['s_trial'].tolist()[np.where(events['trial'] == (n_total_trial//2))[0][-1]]/(n_total_trial//2),\n",
    "            'subject': subject,\n",
    "            'session': session_index+1,\n",
    "        })\n",
    "        successes.append({\n",
    "            'rate': events['s_trial'].tolist()[-1]/n_total_trial,\n",
    "            'subject': subject,\n",
    "            'session': session_index+1,\n",
    "        })\n",
    "half_successes = pd.json_normalize(half_successes)\n",
    "successes = pd.json_normalize(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(data=successes, x='session', y='rate')#, hue='subject')\n",
    "plt.title('Success over all trials')\n",
    "plt.xlim(0, 15)\n",
    "plt.xticks(np.arange(1, 15))\n",
    "plt.savefig(f'{figure_folder}/rate_line.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "sns.boxplot(data=successes, x='session', y='rate', showfliers=False, ax=ax)#, hue='subject')\n",
    "plt.title('Success over all trials')\n",
    "pairs = [(1, 6), (1, 10), (1, 14)]\n",
    "annotator = Annotator(ax, pairs, data=successes, x='session', y='rate')\n",
    "annotator.configure(test=\"t-test_welch\").apply_and_annotate()\n",
    "plt.savefig(f'{figure_folder}/rate_box.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Raster Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9eb8921dcf4bc3a54ccd6498bb8a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe888fb12aed4da5a5c392905aa7f4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfd456565aa432ebdbdb60e1dfeddd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bc986a0c1e44a0aa1ac67745a8b70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6186646d83243c9b5fd616fde8fda97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1ef01284fc43a48ddc071979869dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d96ea98eb4c474fb607148c0c4eebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af2669f599b4547a6efb042c9cd0fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spikeinterface.core as sc \n",
    "import spikeinterface.curation as scu\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "n_segment = 14\n",
    "n_ms_per_s = 1000\n",
    "s_before, s_after = 1, 1\n",
    "\n",
    "for subject, subject_curation in curation.items():\n",
    "    session_info = pd.read_csv(f'data/processed/{subject}/info.csv')\n",
    "    \n",
    "    for region, (threshold, curated_units) in subject_curation.items():\n",
    "        output_folder = f'{figure_folder}/raster-behavior/{region}'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        recordings = [sc.load_extractor(f'data/processed/{subject}/{region}/recordings/segment{segment_index}') for segment_index in range(n_segment)]\n",
    "        recording = sc.concatenate_recordings(recordings)\n",
    "\n",
    "        sorting = se.NpzSortingExtractor(f'data/processed/{subject}/{region}/sortings-{threshold}/sorter_output/firings.npz')\n",
    "        sorting = scu.remove_excess_spikes(sorting, recording)\n",
    "        sortings = sc.split_sorting(sorting, recordings)\n",
    "        sortings = [sc.select_segment_sorting(sortings, segment_indices=segment) for segment in range(len(recordings))]\n",
    "\n",
    "        n_frames_per_ms = int(sorting.sampling_frequency / n_ms_per_s)\n",
    "\n",
    "        for unit_id in tqdm(curated_units):\n",
    "            unit_plot_file = f'{output_folder}/{subject}-{threshold}-{unit_id}.png'\n",
    "            if os.path.isfile(unit_plot_file):\n",
    "                continue\n",
    "        \n",
    "            cue_spike_trains, trigger_spike_trains = [], []\n",
    "            cue_train_counts, trigger_train_counts = [], []\n",
    "            fast_reaction_rates = []\n",
    "            for segment_index in range(n_segment):\n",
    "                segment_info = session_info[session_info['segment_index'] == segment_index]\n",
    "\n",
    "                controller_date = segment_info['segment_path'].item().split('_')[-2]\n",
    "                controller_date = controller_date[2:] + controller_date[:2]\n",
    "                controller_file = f'data/raw/controller/{controller_date}/{subject.replace(\"_\", \"-\")}.TXT'\n",
    "                events = pd.read_csv(controller_file)\n",
    "                # If there are multiple headers that day, the last header marks the start of the actual experiment. This might happen when we use the subject RFID tag duing the equipment check.\n",
    "                state_ids = np.where(events['state'] == 'state')[0]\n",
    "                if len(state_ids) > 0:\n",
    "                    events = events.iloc[state_ids[-1]+1:].reset_index(drop=True)\n",
    "                    \n",
    "                s_trials, f_trials = [], []\n",
    "                reaction_times = {} # in ms\n",
    "                for trial in range(n_total_trial):\n",
    "                    trial_indices = np.where(events['trial'] == trial)[0]\n",
    "                    if any(events['state'][trial_indices] == 1):\n",
    "                        s_trials.append(trial)\n",
    "                        # The first index having \"triggered state\" (1) and event trial number marks the reacted time.\n",
    "                        reaction_time = events['time'].tolist()[np.where((events['state'] == 1) & (events['trial'] == trial))[0][0]]\n",
    "                        # Off set the reaction time to the start of the trial.\n",
    "                        reaction_time -= events['time'].tolist()[trial_indices.min()]\n",
    "                        reaction_times[trial] = reaction_time / n_ms_per_s\n",
    "                    else:\n",
    "                        f_trials.append(trial)\n",
    "                assert len(s_trials) + len(f_trials) == n_total_trial\n",
    "                \n",
    "                trial_starts = eval(segment_info['trial_starts'].item())\n",
    "                trial_ends = eval(segment_info['trial_ends'].item())\n",
    "\n",
    "                unit_spike_train = sortings[segment_index].get_unit_spike_train(unit_id)\n",
    "\n",
    "                segment_cue_spike_trains, segment_trigger_spike_trains = [], []\n",
    "                for trial, (trial_start, trial_end) in enumerate(zip(trial_starts, trial_ends)):\n",
    "                    # In this plots only successful trials have reaction time.\n",
    "                    if trial not in s_trials: continue\n",
    "\n",
    "                    t_cue_start = trial_start - s_before * sorting.sampling_frequency\n",
    "                    t_cue_end = trial_start + s_after * sorting.sampling_frequency\n",
    "\n",
    "                    cue_spike_train = unit_spike_train[(unit_spike_train >= t_cue_start) & (unit_spike_train <= t_cue_end)] - trial_start\n",
    "                    cue_spike_train = cue_spike_train / sorting.sampling_frequency\n",
    "                    segment_cue_spike_trains.append(cue_spike_train)\n",
    "\n",
    "                    trigger_time = int(trial_start + reaction_times[trial] * sorting.sampling_frequency)\n",
    "                    t_trigger_start = trigger_time - s_before * sorting.sampling_frequency\n",
    "                    t_trigger_end = trigger_time + s_after * sorting.sampling_frequency\n",
    "\n",
    "                    trigger_spike_train = unit_spike_train[(unit_spike_train >= t_trigger_start) & (unit_spike_train <= t_trigger_end)] - trigger_time\n",
    "                    trigger_spike_train = trigger_spike_train / sorting.sampling_frequency\n",
    "                    segment_trigger_spike_trains.append(trigger_spike_train)\n",
    "                \n",
    "                cue_spike_trains.extend(segment_cue_spike_trains)\n",
    "                trigger_spike_trains.extend(segment_trigger_spike_trains)\n",
    "\n",
    "                cue_train_counts.append(len(cue_spike_trains))\n",
    "                trigger_train_counts.append(len(trigger_spike_trains))\n",
    "                fast_reaction_rates.append(len([v for v in reaction_times.values() if v < 1]) / len(s_trials) * 100)\n",
    "\n",
    "            fig = plt.figure(figsize=(7, 6))\n",
    "            fig.suptitle(f'{subject} - {region} - {unit_id}')\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            ax.eventplot(cue_spike_trains)\n",
    "            for segment_index, y in enumerate(cue_train_counts):\n",
    "                ax.axhline(y=y, color='black', linestyle='--', alpha=1, linewidth=0.5)\n",
    "                ax.text(s_after+0.3, y, f'{segment_index+1}')\n",
    "            ax.set_ylabel('trials')\n",
    "            ax.set_title('relative to cue')\n",
    "            ax.set_xticks([-s_before, 0, s_after])\n",
    "            \n",
    "            ax = plt.subplot(1, 2, 2)\n",
    "            ax.eventplot(trigger_spike_trains)\n",
    "            for segment_index, y in enumerate(trigger_train_counts):\n",
    "                ax.axhline(y=y, color='black', linestyle='--', alpha=1, linewidth=0.5)\n",
    "                ax.text(s_after+0.3, y, f'{segment_index+1} {fast_reaction_rates[segment_index]:.2f}%')\n",
    "            ax.set_ylabel('trials')\n",
    "            ax.set_title('relative to trigger')\n",
    "            ax.set_xticks([-s_before, 0, s_after])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(unit_plot_file)#, transparent=True)\n",
    "            # plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Heatmap Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa430562a4d344ac9ba8e518483220d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb4703730fc42f58eb7469bcf08d31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5ad835edb44005bc6d7b621cbd1724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de462770a0094063923be9bc30bb7962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537a775ef5d04e30bcd7dcce8146c4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spikeinterface.core as sc \n",
    "import spikeinterface.curation as scu\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "n_segment = 14\n",
    "n_ms_per_s = 1000\n",
    "s_before, s_after = 1, 1\n",
    "bin_size_ms = 100\n",
    "\n",
    "for subject, subject_curation in curation.items():\n",
    "    session_info = pd.read_csv(f'data/processed/{subject}/info.csv')\n",
    "    \n",
    "    for region, (threshold, curated_units) in subject_curation.items():\n",
    "        output_folder = f'{figure_folder}/heatmap-behavior-{bin_size_ms}ms/{region}'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        recordings = [sc.load_extractor(f'data/processed/{subject}/{region}/recordings/segment{segment_index}') for segment_index in range(n_segment)]\n",
    "        recording = sc.concatenate_recordings(recordings)\n",
    "\n",
    "        sorting = se.NpzSortingExtractor(f'data/processed/{subject}/{region}/sortings-{threshold}/sorter_output/firings.npz')\n",
    "        sorting = scu.remove_excess_spikes(sorting, recording)\n",
    "        sortings = sc.split_sorting(sorting, recordings)\n",
    "        sortings = [sc.select_segment_sorting(sortings, segment_indices=segment) for segment in range(len(recordings))]\n",
    "\n",
    "        n_frames_per_ms = int(sorting.sampling_frequency / n_ms_per_s)\n",
    "\n",
    "        for unit_id in tqdm(curated_units):\n",
    "            unit_plot_file = f'{output_folder}/{subject}-{threshold}-{unit_id}.png'\n",
    "            if os.path.isfile(unit_plot_file):\n",
    "                continue\n",
    "        \n",
    "            spike_bins = []\n",
    "        \n",
    "            for segment_index in range(n_segment):\n",
    "                segment_info = session_info[session_info['segment_index'] == segment_index]\n",
    "\n",
    "                controller_date = segment_info['segment_path'].item().split('_')[-2]\n",
    "                controller_date = controller_date[2:] + controller_date[:2]\n",
    "                controller_file = f'data/raw/controller/{controller_date}/{subject.replace(\"_\", \"-\")}.TXT'\n",
    "                events = pd.read_csv(controller_file)\n",
    "                # If there are multiple headers that day, the last header marks the start of the actual experiment. This might happen when we use the subject RFID tag duing the equipment check.\n",
    "                state_ids = np.where(events['state'] == 'state')[0]\n",
    "                if len(state_ids) > 0:\n",
    "                    events = events.iloc[state_ids[-1]+1:].reset_index(drop=True)\n",
    "                    \n",
    "                s_trials, f_trials = [], []\n",
    "                reaction_times = {} # in ms\n",
    "                for trial in range(n_total_trial):\n",
    "                    trial_indices = np.where(events['trial'] == trial)[0]\n",
    "                    if any(events['state'][trial_indices] == 1):\n",
    "                        s_trials.append(trial)\n",
    "                        # The first index having \"triggered state\" (1) and event trial number marks the reacted time.\n",
    "                        reaction_time = events['time'].tolist()[np.where((events['state'] == 1) & (events['trial'] == trial))[0][0]]\n",
    "                        # Off set the reaction time to the start of the trial.\n",
    "                        reaction_time -= events['time'].tolist()[trial_indices.min()]\n",
    "                        reaction_times[trial] = reaction_time / n_ms_per_s\n",
    "                    else:\n",
    "                        f_trials.append(trial)\n",
    "                assert len(s_trials) + len(f_trials) == n_total_trial\n",
    "                \n",
    "                trial_starts = eval(segment_info['trial_starts'].item())\n",
    "                trial_ends = eval(segment_info['trial_ends'].item())\n",
    "\n",
    "                unit_spike_train = sortings[segment_index].get_unit_spike_train(unit_id)\n",
    "\n",
    "                segment_cue_spike_bins, segment_trigger_spike_bins = [], []\n",
    "                for trial, (trial_start, trial_end) in enumerate(zip(trial_starts, trial_ends)):\n",
    "                    # In this plots only successful trials have reaction time.\n",
    "                    if trial not in s_trials: continue\n",
    "\n",
    "                    t_cue_start = trial_start - s_before * sorting.sampling_frequency\n",
    "                    t_cue_end = trial_start + s_after * sorting.sampling_frequency\n",
    "\n",
    "                    cue_spike_train = unit_spike_train[(unit_spike_train >= t_cue_start) & (unit_spike_train <= t_cue_end)] - trial_start\n",
    "                    cue_spike_train = cue_spike_train / sorting.sampling_frequency\n",
    "                    cue_spike_bin = np.histogram(cue_spike_train, bins=np.arange(-s_before, s_after+1e-6, bin_size_ms/n_ms_per_s))[0]\n",
    "                    segment_cue_spike_bins.append(cue_spike_bin)\n",
    "\n",
    "                    reward_time = int(trial_start + (reaction_times[trial] + 1) * sorting.sampling_frequency)\n",
    "                    t_trigger_start = reward_time # - s_before * sorting.sampling_frequency\n",
    "                    t_trigger_end = reward_time + (s_before + s_after) * sorting.sampling_frequency\n",
    "\n",
    "                    trigger_spike_train = unit_spike_train[(unit_spike_train >= t_trigger_start) & (unit_spike_train <= t_trigger_end)] - reward_time\n",
    "                    trigger_spike_train = trigger_spike_train / sorting.sampling_frequency\n",
    "                    trigger_spike_bin = np.histogram(trigger_spike_train, bins=np.arange(0, (s_before + s_after)+1e-6, bin_size_ms/n_ms_per_s))[0]\n",
    "                    segment_trigger_spike_bins.append(trigger_spike_bin)\n",
    "                \n",
    "                segment_cue_spike_bins = np.array(segment_cue_spike_bins)\n",
    "                segment_trigger_spike_bins = np.array(segment_trigger_spike_bins)\n",
    "\n",
    "                segment_bins = np.hstack([segment_cue_spike_bins, segment_trigger_spike_bins])\n",
    "                segment_bins = (segment_bins - segment_bins.mean()) / (segment_bins.std() + 1e-6)\n",
    "\n",
    "                spike_bins.append(segment_bins.mean(0))\n",
    "            \n",
    "\n",
    "            spike_bins = np.array(spike_bins)\n",
    "            cue_spike_bins = spike_bins[:, :spike_bins.shape[1] // 2]\n",
    "            trigger_spike_bins = spike_bins[:, spike_bins.shape[1] // 2:]\n",
    "\n",
    "            vlim = 0.5\n",
    "            fig = plt.figure(figsize=(10, 6))\n",
    "            fig.suptitle(f'{subject} - {region} - {unit_id}')\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            sns.heatmap(cue_spike_bins, cmap=plt.cm.bwr, vmin=-vlim, vmax=vlim)\n",
    "            ax.set_ylabel('sessions')\n",
    "            ax.set_title('relative to cue')\n",
    "            ax.set_xticks([0, cue_spike_bins.shape[1]//2, cue_spike_bins.shape[1]], [-s_before, 0, s_after])\n",
    "\n",
    "            ax = plt.subplot(1, 2, 2)\n",
    "            sns.heatmap(trigger_spike_bins, cmap=plt.cm.bwr, vmin=-vlim, vmax=vlim)\n",
    "            ax.set_ylabel('sessions')\n",
    "            ax.set_title('relative to reward')\n",
    "            ax.set_xticks([0, trigger_spike_bins.shape[1]//2, trigger_spike_bins.shape[1]], [0, (s_before+s_after)//2, (s_before+s_after)])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(unit_plot_file)#, transparent=True)\n",
    "            # plt.show()\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si-0.98.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
